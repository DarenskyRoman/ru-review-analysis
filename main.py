import streamlit as st
import re
import pandas as pd
from nltk.probability import FreqDist
from nltk.util import ngrams
from pymystem3 import Mystem
from razdel import tokenize
from transformers import pipeline


@st.cache_data
def predict(text):
    mapping = {"neutral": 0, "positive": 1, "negative": 2}
    result = mapping[model(text)[0]["label"]]
    return result

@st.cache_data
def text_prepocessing(text, do_lemm=False):
    text = text.lower()
    text = re.sub(r'[^\u0400-\u04FF]', ' ', text)

    text_tokens = list(tokenize(text))
    text_tokens = [_.text for _ in text_tokens]
    
    text_tokens = [word for word in text_tokens if len(word) > 1]
    if do_lemm:
        text_tokens = [stem.lemmatize(token)[0] for token in text_tokens]
    text = ' '.join(text_tokens)

    return text


@st.cache_data
def do_analysis(text):
    if text == '' or text == None:
        return "–ñ–¥—ë–º –≤–≤–æ–¥ üïí"

    result = predict(text_prepocessing(text))
    
    if result == 1:
        result = "–ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ üôÇ"
    if result == 0:
        result = "–ù–µ–π—Ç—Ä–∞–ª—å–Ω–æ üòê"
    if result == 2:
        result = "–ù–µ–≥–∞—Ç–∏–≤–Ω–µ–Ω—å–∫–æ ‚òπÔ∏è"

    return result


@st.cache_data
def ngramming(df_positive, df_neutral, df_negative):
    df_positive = " ".join(df_positive)
    df_neutral = " ".join(df_neutral)
    df_negative = " ".join(df_negative)

    df_positive = text_prepocessing(df_positive, do_lemm=False)
    df_neutral = text_prepocessing(df_neutral, do_lemm=False)
    df_negative = text_prepocessing(df_negative, do_lemm=False)

    st.write("–ü–æ–∑–∏—Ç–∏–≤–Ω—ã–µ üôÇ n-–≥—Ä–∞–º–º—ã:\n")
    ngramm_extraction(df_positive)
    st.write("–ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–µ üòê n-–≥—Ä–∞–º–º—ã:\n")
    ngramm_extraction(df_neutral)
    st.write("–ù–µ–≥–∞—Ç–∏–≤–Ω—ã–µ ‚òπÔ∏è n-–≥—Ä–∞–º–º—ã:\n")
    ngramm_extraction(df_negative)

@st.cache_data
def ngramm_extraction(text):
    one = list(ngrams(text.split(), 1))
    two = list(ngrams(text.split(), 2))
    three = list(ngrams(text.split(), 3))

    fdist_one = FreqDist(one).most_common(5)
    fdist_two = FreqDist(two).most_common(5)
    fdist_three = FreqDist(three).most_common(5)

    fdist_one = ''.join(f" {' '.join(item[0])} - {item[1]} | " for item in fdist_one)
    fdist_two = ''.join(f" {' '.join(item[0])} - {item[1]} | " for item in fdist_two)
    fdist_three = ''.join(f" {' '.join(item[0])} - {item[1]} | " for item in fdist_three)

    st.write("–£–Ω–∏–≥—Ä–∞–º–º—ã:")
    st.write(fdist_one)

    st.write("–ë–∏–≥—Ä–∞–º–º—ã:")
    st.write(fdist_two)

    st.write("–¢—Ä–∏–≥—Ä–∞–º–º—ã:")
    st.write(fdist_three)

@st.cache_data
def file_analisys(file, reviews_number, column_name, shuffle, do_ngramms):
    try:
        if shuffle:
            df = pd.read_csv(file, usecols=[column_name]).sample(n=reviews_number)
        else:
            df = pd.read_csv(file, usecols=[column_name], nrows=reviews_number)

        df["predict"] = df["review"].apply(predict)

        df_positive = df["review"][df["predict"] == 1]
        df_neutral = df["review"][df["predict"] == 0]
        df_negative = df["review"][df["predict"] == 2]

        st.write(df.head(5))

        st.write(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö üôÇ –≤—ã—Ä–∞–∂–µ–Ω–∏–π: {df_positive.count()}")
        st.write(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã—Ö üòê –≤—ã—Ä–∞–∂–µ–Ω–∏–π: {df_neutral.count()}")
        st.write(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö ‚òπÔ∏è –≤—ã—Ä–∞–∂–µ–Ω–∏–π: {df_negative.count()}")

        if do_ngramms:
            ngramming(df_positive, df_neutral, df_negative)

        return df.to_csv()

    except:
        st.warning("–ù–µ –º–æ–∂–µ–º –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª ‚òπÔ∏è. –í—Å—ë –ª–∏ –≤—ã –≤–≤–µ–ª–∏ –≤–µ—Ä–Ω–æ?")
        return "–û–Ω–µ—Ç"

@st.cache_resource
def load_model():
    return pipeline(model="seara/rubert-tiny2-russian-sentiment")

@st.cache_resource
def load_lemmatizer():
    return Mystem()

def check_prep():
    if file == None or (column_name == '' or column_name == None):
        return 0
    else:
        return 1


stem = load_lemmatizer()
model = load_model()

st.title("–ê–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –≤—ã—Ä–∞–∂–µ–Ω–∏–π")

st.write("\n\n")
st.write("\n\n ##### –û–¥–Ω–æ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ")

st.write("""
        –í–≤–µ–¥–∏—Ç–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –≤ –ø–æ–ª–µ –Ω–∏–∂–µ –∏ —É–≤–∏–¥—å—Ç–µ –µ–≥–æ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å.
         
        –ü—Ä–æ–≥—Ä–∞–º–º–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç –¥–ª—è –≤—ã—Ä–∞–∂–µ–Ω–∏–π, –Ω–∞–ø–∏—Å–∞–Ω–Ω—ã—Ö –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.
        """)

text = st.text_area(label="–Ø –ø–æ–ª–µ –Ω–∏–∂–µ", placeholder="–û—Ç–∑—ã–≤ —Å—é–¥–∞")

st.write(f"##### –†–µ–∑—É–ª—å—Ç–∞—Ç: {do_analysis(text)}")

st.write("\n\n")
st.write("\n\n ##### –ú–Ω–æ–≥–æ –≤—ã—Ä–∞–∂–µ–Ω–∏–π")

st.write("""
        –ï—â—ë –≤—ã –º–æ–∂–µ—Ç–µ –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç –≤—ã—Ä–∞–∂–µ–Ω–∏–π –≤ —Ñ–æ—Ä–º–∞—Ç–µ csv.
         
        –ü—Ä–æ–≥—Ä–∞–º–º–∞ –≤—ã–≤–µ–¥–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö, –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö –∏ –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π,
        –∞ —Ç–∞–∫–∂–µ (–ø–æ –∂–µ–ª–∞–Ω–∏—é) –Ω–∞–±–æ—Ä —á–∞—Å—Ç–æ –≤—Å—Ç—Ä–µ—á–∞—é—â–∏—Ö—Å—è 1, 2 –∏ 3-–≥—Ä–∞–º–º.
        """)

file = st.file_uploader(label="–Ø –∑–∞–≥—Ä—É–∂–∞—é —Ñ–∞–π–ª—ã", type="csv")

st.write("""
        ###### –ü–µ—Ä–µ–¥ –∞–Ω–∞–ª–∏–∑–æ–º –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –∫–æ–µ-—á—Ç–æ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –Ω–∏–∂–µ:
        """)

reviews_number = st.number_input(label="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞", min_value=1, max_value=1000, value="min", step=1)
column_name = st.text_input(label="–ù–∞–∑–≤–∞–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–∞ —Å –≤—ã—Ä–∞–∂–µ–Ω–∏—è–º–∏", value="gugu gaga")
shuffle = st.checkbox(label="–ü–µ—Ä–µ–º–µ—à–∏–≤–∞–µ–º? P.S. –ü–æ–ª–µ–∑–Ω–æ, –µ—Å–ª–∏ –≤—ã—Ä–∞–∂–µ–Ω–∏—è –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ —Å–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞–Ω–Ω—ã –ø–æ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ (–∏–¥—É—Ç –ø–æ–¥—Ä—è–¥)")
do_ngramms = st.checkbox(label="–í—ã–≤–æ–¥–∏–º n-–≥—Ä–∞–º–º—ã?")

if check_prep() == 0:
    st.button(label="–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å", disabled=True)
else:
    bupton = st.button(label="–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å", disabled=False)
    if bupton:
        file_result = file_analisys(file, reviews_number, column_name, shuffle, do_ngramms)
        if file_result != "–û–Ω–µ—Ç":
            st.write("""
                ###### –•–æ—Ç–∏—Ç–µ —Å–∫–∞—á–∞—Ç—å –ø–æ–ª—É—á–∏–≤—à–∏–π—Å—è —Ñ–∞–π–ª?
                """)
            st.download_button(
                label="–î–∞, —Ö–æ—á—É",
                data=file_result,
                file_name='result.csv',
                mime='text/csv',
            )
